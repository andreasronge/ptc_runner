# examples/rlm/run.exs

# This script runs the RLM (Recursive Language Model) pattern using real LLMs.
# It uses a "Planner" SubAgent (Sonnet 4.5) to decide how to analyze the large test_corpus.log
# and spawns parallel "Worker" SubAgents (Haiku 4.5) to process the chunks recursively.

defmodule RLM.Runner do
  alias PtcRunner.SubAgent

  def run do
    # 0. Load AWS Credentials if needed (for Bedrock)
    if System.get_env("AWS_PROFILE") == "sandbox" and is_nil(System.get_env("AWS_ACCESS_KEY_ID")) do
      IO.puts("Loading AWS credentials from profile 'sandbox'...")

      {output, 0} =
        System.cmd("aws", [
          "configure",
          "export-credentials",
          "--profile",
          "sandbox",
          "--format",
          "env"
        ])

      output
      |> String.split("\n")
      |> Enum.each(fn line ->
        case Regex.run(
               ~r/export (AWS_ACCESS_KEY_ID|AWS_SECRET_ACCESS_KEY|AWS_SESSION_TOKEN)=(.+)/,
               line
             ) do
          [_, key, value] -> System.put_env(key, value)
          _ -> :ok
        end
      end)

      System.put_env("AWS_REGION", "eu-west-1")
    end

    # 1. Load the large corpus (Generated by gen_data.exs)
    corpus_path = "examples/rlm/test_corpus.log"

    unless File.exists?(corpus_path) do
      IO.puts("Generating 10,000 line corpus...")
      System.put_env("N_LINES", "10000")
      Code.require_file("examples/rlm/gen_data.exs")
    end

    corpus = File.read!(corpus_path)

    # 2. Define the Recursive Worker Agent
    # This agent analyzes a chunk. It uses Haiku 4.5 for cost-effective parallel processing.
    # The :self sentinel enables clean recursive invocation without Agent registry hacks.

    worker_agent =
      SubAgent.new(
        prompt: """
        TASK: Analyze the log chunk in data/chunk for CRITICAL or ERROR incidents.
        CURRENT_DEPTH: {{_depth}}

        STRATEGY:
        1. If the chunk is small enough (< 1500 lines), analyze it directly using Cloujure logic.
        2. If the chunk is massive, use the 'worker' tool to subdivide it into smaller parallel tasks.
        3. Use 'pmap' for parallel tool calls to maximize efficiency.
        4. Always return results in the format: {incidents [:string]}
        """,
        signature: "(chunk :string, _depth :int) -> {incidents [:string]}",
        description:
          "Analyze a log chunk for incidents. Use this tool recursively for large chunks by subdividing them.",
        tools: %{"worker" => :self},
        max_turns: 5,
        max_depth: 3,
        llm: LLMClient.callback("bedrock:haiku")
      )

    # Wrap worker agent as a tool for the planner
    worker_tool = SubAgent.as_tool(worker_agent)

    # 3. Define the Planner (The Orchestrator)
    # The planner uses Sonnet 4.5 to perform high-level strategy.

    planner_llm = LLMClient.callback("bedrock:sonnet")

    # 4. Run the Root Orchestrator
    IO.puts("\n=== Starting TRUE RLM Orchestration (Sonnet 4.5 -> Haiku 4.5) ===\n")

    run_opts = [
      context: %{"corpus" => corpus},
      tools: %{"worker" => worker_tool},
      llm: planner_llm,
      max_turns: 10,
      max_heap: 20_000_000
    ]

    # Explicit instruction to the Planner to use the worker tool
    planner_prompt = """
    Audit the system logs in data/corpus.

    You have access to a 'worker' tool that can process log chunks in parallel.
    YOUR TASK:
    1. Partition the large corpus into approximately 2000-line blocks.
    2. Use 'pmap' with the 'worker' tool to analyze all blocks concurrently.
    3. Flatten and aggregate the results into a final report.
    4. Provide the total incident count and a list of the first 10 unique incidents found.
    """

    case SubAgent.run(planner_prompt, run_opts) do
      {:ok, step} ->
        IO.puts("\n=== RLM Audit Complete ===")
        IO.inspect(step.return, pretty: true)

        IO.puts("\nExecution Metrics:")
        IO.puts("  Total LLM Requests: #{step.usage.llm_requests}")
        IO.puts("  Duration: #{step.usage.duration_ms}ms")

        if step.prints != [] do
          IO.puts("\nIntermediate Logs:")
          IO.puts(Enum.join(step.prints, ""))
        end

      {:error, step} ->
        IO.puts("\n=== RLM Audit Failed ===")
        IO.inspect(step.fail)

        if step.turns != [] do
          IO.puts("\nLast Turn Result:")
          IO.inspect(List.last(step.turns).result)
        end
    end
  end
end

RLM.Runner.run()
