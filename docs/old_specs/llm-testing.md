# LLM Testing & Benchmarks

This document describes how PtcRunner programs can be generated by LLMs and the different approaches for providing schema information to the model.

## Overview

**E2E tests** in this project are tests that call real LLM APIs (OpenRouter). They're excluded by default (`@moduletag :e2e`) because they:
- Require API keys (`OPENROUTER_API_KEY`)
- Cost money per call
- Are non-deterministic (LLM responses vary)

PtcRunner provides three ways to describe the DSL to an LLM:

| Mode | Function | Token Size | Use Case |
|------|----------|------------|----------|
| **Text Mode** | `Schema.to_prompt()` | ~400 tokens | Compact, human-readable prompt |
| **LLM Schema Mode** | `Schema.to_llm_schema()` | ~7,500 tokens | Structured output with JSON schema |
| **Full JSON Schema** | `Schema.to_json_schema()` | ~8,000 tokens | Validation, documentation |

## Text Mode

Uses a compact, human-readable description of all operations (~400 tokens).

```elixir
prompt = """
You are generating a PTC program.

#{PtcRunner.Schema.to_prompt()}

Task: Find the employee who has been employed the longest

Respond with ONLY valid JSON.
"""

text = ReqLLM.generate_text!("openrouter:google/gemini-2.5-flash", prompt)
```

**Example prompt output:**
```
PTC Operations (JSON format, wrap in {"program": ...}):

Data: load(name), literal(value), var(name)
Flow: pipe(steps), let(in,name,value), if(condition,else,then)
Filter/Transform: filter(where), map(expr), select(fields), reject(where), sort_by(field)
Compare: eq(field,value), neq(field,value), gt(field,value), ...
Aggregate: count, sum(field), avg(field), min(field), max(field), min_by(field), max_by(field), first, last, nth(index)
...

Examples:
{"program":{"op":"pipe","steps":[{"op":"load","name":"orders"},{"op":"filter","where":{"op":"gt","field":"total","value":100}},{"op":"count"}]}}
```

**Pros:**
- Very small token footprint (~400 tokens)
- Fast and cheap
- Works well with capable models

**Cons:**
- No structured output guarantee
- May need response cleanup (markdown fences, etc.)
- Less precise than JSON schema

## LLM Schema Mode (Structured Output)

Uses a flattened JSON schema designed for LLM structured output APIs (~7,500 tokens). This schema uses `anyOf` instead of `$ref` for better LLM compatibility.

```elixir
prompt = "Generate a PTC program for: Find products over $100"
schema = PtcRunner.Schema.to_llm_schema()

result = ReqLLM.generate_object!("openrouter:google/gemini-2.5-flash", prompt, schema)
```

**Pros:**
- Guaranteed valid JSON structure
- No response cleanup needed
- Schema guides the model's output

**Cons:**
- Large token footprint (~7,500 tokens input)
- ~10x more expensive than text mode
- Some providers don't support structured output

## Full JSON Schema

The canonical JSON schema with `$ref` references, suitable for validation and documentation.

```elixir
schema = PtcRunner.Schema.to_json_schema()
# Saved to priv/ptc_schema.json
```

This schema is primarily used for:
- Validating programs externally
- Documentation generation
- IDE support / autocomplete

## Benchmark Results

Tested with 11 test cases × 2 iterations per model:

| Model | Pass Rate | Cost (22 tests) | Avg Latency |
|-------|-----------|-----------------|-------------|
| **gemini-2.5-flash** | **100%** | $0.0050 | ~550ms |
| deepseek-v3.2 | 86% | $0.0028 | ~1,800ms |
| kimi-linear-48b-a3b-instruct | 68% | $0.0044 | ~850ms |

### Per-Test Results

| Test | Description | Gemini | DeepSeek | Moonshot |
|------|-------------|--------|----------|----------|
| filter_gt | Filter where price > 10 | ✓ | ✓ | ✓ |
| sum_prices | Sum all prices | ✓ | ✓ | ✓ |
| filter_and_count | Filter + count | ✓ | ✓ | ✓ |
| max_by | Find row with max value | ✓ | ✓ | ✓ |
| min_by | Find row with min value | ✓ | ✓ | ~50% |
| pluck_names | Extract field from each item | ✓ | ✓ | ✗ |
| sort_by | Sort ascending | ✓ | ✓ | ✓ |
| sort_desc_first | Sort descending + first | ✓ | ~50% | ✗ |
| filter_sort_first | Filter + sort + first | ✓ | ✓ | ✓ |
| max_value_vs_row | Get max value (not row) | ✓ | ✓ | ✓ |
| nested_get | Nested path access | ✓ | ~50% | ✗ |

### Key Findings

1. **Gemini 2.5 Flash** handles all DSL patterns correctly, including:
   - `sort_by` with `order: "desc"`
   - `get` with both `field` and `path` parameters
   - Complex multi-step pipelines

2. **Common failure patterns** in weaker models:
   - Using `path: "user.address.city"` instead of `path: ["user", "address", "city"]`
   - Ignoring `order: "desc"` parameter
   - Using `select` instead of `map` + `get` for field extraction

3. **Cost comparison** (text mode):
   - Gemini: ~$0.00023 per test
   - DeepSeek: ~$0.00013 per test (cheapest)
   - Structured mode is ~10x more expensive due to schema size

## Running Benchmarks

```bash
# Run default benchmark (3 models × 11 tests × 3 iterations)
MIX_ENV=test mix run -e 'PtcRunner.TestSupport.LLMBenchmark.run()'

# Custom configuration
MIX_ENV=test mix run -e '
  PtcRunner.TestSupport.LLMBenchmark.run(
    models: ["openrouter:google/gemini-2.5-flash"],
    iterations: 5,
    tests: ["filter_gt", "max_by", "nested_get"],
    pricing: %{"claude-haiku" => {0.25, 1.25}}
  )
'
```

### Configuration Options

| Option | Description | Default |
|--------|-------------|---------|
| `:models` | List of model identifiers | 3 default models |
| `:iterations` | Runs per test | 3 |
| `:tests` | Test names or `:all` | `:all` |
| `:pricing` | Custom pricing `%{model => {input, output}}` | Built-in prices |

### Adding Custom Tests

Tests are defined in `test/support/llm_benchmark.ex`:

```elixir
%{
  name: "my_test",
  task: "Natural language description of what to do",
  input: [%{"field" => "value"}, ...],
  validator: :my_validator
}
```

## Test Files

- `test/ptc_runner/e2e_test.exs` - ExUnit E2E tests (text_mode, structured_mode tags)
- `test/support/llm_benchmark.ex` - Benchmark utility for model comparison
- `test/support/llm_client.ex` - LLM client wrapper for tests

## Environment Setup

```bash
# Required for E2E tests
export OPENROUTER_API_KEY=sk-or-...

# Run E2E tests
mix test --only text_mode
mix test --only structured_mode
```
