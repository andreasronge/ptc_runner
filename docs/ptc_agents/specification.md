# PtcRunner.SubAgent Specification

> **Status:** Draft specification based on spike validation (branch: `spike-subagent`)

This document specifies the core SubAgent API for inclusion in the PtcRunner library.

## Overview

A SubAgent is an isolated worker that executes tasks using PTC-Lisp programs generated by an LLM. The core library provides:

- **`PtcRunner.SubAgent`** - Main API for task delegation
- **`PtcRunner.SubAgent.Loop`** - Multi-turn agentic execution
- **`PtcRunner.SubAgent.RefExtractor`** - Deterministic value extraction

The LLM integration is callback-based with no external dependencies.

## Module Structure

```
lib/ptc_runner/
├── sub_agent.ex                 # Main API
└── sub_agent/
    ├── loop.ex                  # Agentic loop implementation
    ├── ref_extractor.ex         # Value extraction from results
    ├── prompt.ex                # System prompt generation
    ├── schema_extractor.ex      # Tool type extraction from @spec
    └── llm_tool.ex              # LLM-powered tool wrapper
```

---

## Architecture Overview

### Execution Flow

```
delegate/2
    │
    ├─► Prompt.generate/1 ──► Extract schemas from tools + tool_catalog
    │                         Generate system prompt with tool signatures
    │
    └─► Loop.run/2
            │
            ├─► LLM callback ──► Returns program or answer
            │
            ├─► PtcRunner.Lisp.run/2 ──► Execute PTC-Lisp program
            │       │
            │       └─► Tool calls recorded for trace
            │
            └─► Loop until answer (no program) or max_turns
                    │
                    └─► RefExtractor.extract/2 ──► Extract refs from result
```

### Tool Schema Extraction

The system automatically extracts type information from tools to include in the LLM prompt:

1. **Function references** (`&MyModule.fun/1`): Extract `@spec` via `Code.Typespec.fetch_specs/1`
2. **Explicit specs** (`{&fun/1, "..."}`): Use provided schema string
3. **Skip marker** (`{&fun/1, :skip}`): No schema, no validation
4. **Anonymous functions**: No schema available (warning logged)

Extracted schemas are formatted for the LLM:
```
search(query :string, limit :int) -> [{:id :int :title :string}]
```

### tools vs tool_catalog

| Aspect | `tools` | `tool_catalog` |
|--------|---------|----------------|
| Schema in prompt | ✓ "Tools you can call" | ✓ "Tools for planning (do not call)" |
| Callable by agent | ✓ Yes | ✗ No |
| Use case | Execution tools | Planning visibility |

This separation enables planning agents to see what tools exist (with types) without being able to call them prematurely.

---

## API Specification

### PtcRunner.SubAgent

```elixir
defmodule PtcRunner.SubAgent do
  @moduledoc """
  Isolated task execution with context efficiency.

  SubAgents execute tasks using PTC-Lisp programs generated by an LLM.
  Each SubAgent runs in isolation with its own tools, context, and memory.

  ## Example

      llm = fn %{system: sys, messages: msgs} ->
        # Call your LLM provider
        {:ok, "```clojure\\n(call \\"get_data\\" {})\\n```"}
      end

      {:ok, result} = PtcRunner.SubAgent.delegate(
        "Find the top customer",
        llm: llm,
        tools: %{"get_customers" => &MyApp.get_customers/1}
      )

      result.summary  #=> "Top customer is Acme Corp with $1.2M revenue"
  """

  # ============================================================
  # Types
  # ============================================================

  @typedoc "LLM callback function"
  @type llm :: (llm_input() -> {:ok, String.t()} | {:error, term()})

  @typedoc "Input passed to LLM callback"
  @type llm_input :: %{
    required(:system) => String.t(),
    required(:messages) => [message()]
  }

  @typedoc "Conversation message"
  @type message :: %{
    required(:role) => :user | :assistant,
    required(:content) => String.t()
  }

  @typedoc "Tool function - receives args map, returns any term"
  @type tool :: (map() -> term())

  @typedoc "Ref extractor - Access path or function"
  @type ref_spec :: [Access.access_fun(term(), term())] | (term() -> term())

  @typedoc "Successful result"
  @type result :: %{
    required(:result) => term(),
    required(:summary) => String.t() | nil,
    required(:refs) => map(),
    required(:trace) => [trace_entry()],
    required(:usage) => usage()
  }

  @typedoc "Single turn in execution trace"
  @type trace_entry :: %{
    required(:iteration) => pos_integer(),
    optional(:program) => String.t(),
    optional(:result) => term(),
    optional(:error) => term(),
    optional(:answer) => String.t(),
    optional(:tool_calls) => [tool_call()],
    required(:usage) => usage()
  }

  @typedoc "Tool call record"
  @type tool_call :: %{
    required(:name) => String.t(),
    required(:args) => map(),
    required(:result) => term()
  }

  @typedoc "Token usage statistics"
  @type usage :: %{
    required(:input_tokens) => non_neg_integer(),
    required(:output_tokens) => non_neg_integer(),
    required(:total_tokens) => non_neg_integer(),
    required(:requests) => non_neg_integer()
  }

  @typedoc "Error result"
  @type error :: %{
    required(:reason) => term(),
    required(:trace) => [trace_entry()],
    required(:usage) => usage()
  }

  # ============================================================
  # Main API
  # ============================================================

  @doc """
  Delegate a task to an isolated sub-agent.

  The sub-agent generates PTC-Lisp programs to accomplish the task,
  executing them in a sandboxed environment with access to the
  provided tools.

  ## Required Options

  - `:llm` - Callback function for LLM calls (see `t:llm/0`)

  ## Options

  - `:tools` - Map of tool name (string) to function (default: `%{}`)
  - `:tool_catalog` - Map of tools whose schemas are visible in prompt but not callable (default: `%{}`).
    Useful for planning agents that need to see tool signatures without executing them.
  - `:context` - Values available as `ctx/key` in PTC-Lisp (default: `%{}`)
  - `:refs` - Extraction specs for result values (default: `%{}`)
  - `:max_turns` - Maximum LLM calls before failing (default: `5`)
  - `:timeout` - Per-program execution timeout in ms (default: `5000`)
  - `:max_ref_retries` - Retries if required refs are nil (default: `1`)

  ## Return Value

  On success, returns `{:ok, result}` where result contains:

  - `:result` - The final computed value
  - `:summary` - Human-readable summary from LLM
  - `:refs` - Extracted reference values for chaining
  - `:trace` - Execution trace for debugging
  - `:usage` - Token usage statistics

  On failure, returns `{:error, error}` with reason and trace.

  ## Examples

      # Basic usage
      {:ok, result} = PtcRunner.SubAgent.delegate(
        "List all products",
        llm: my_llm,
        tools: %{"get_products" => &Shop.list_products/1}
      )

      # With refs for chaining
      {:ok, result} = PtcRunner.SubAgent.delegate(
        "Find urgent emails",
        llm: my_llm,
        tools: email_tools,
        refs: %{
          email_ids: fn r -> Enum.map(r, & &1[:id]) end,
          count: &length/1
        }
      )

      # Pass refs to next step
      {:ok, step2} = PtcRunner.SubAgent.delegate(
        "Draft replies",
        llm: my_llm,
        tools: draft_tools,
        context: %{email_ids: result.refs.email_ids}
      )
  """
  @spec delegate(String.t(), keyword()) :: {:ok, result()} | {:error, error()}
  def delegate(task, opts)

  @doc """
  Wrap a SubAgent configuration as a callable tool.

  Returns a function that can be used as a tool in another SubAgent,
  enabling hierarchical agent orchestration.

  ## Options

  Same as `delegate/2`, except `:llm` can be provided here or at call time.

  ## Example

      customer_agent = PtcRunner.SubAgent.as_tool(
        llm: my_llm,
        tools: %{"search" => &CRM.search/1},
        refs: %{customer_id: [Access.at(0), :id]}
      )

      # Use in parent agent
      {:ok, result} = PtcRunner.SubAgent.delegate(
        "Find top customer and their orders",
        llm: my_llm,
        tools: %{
          "customer-finder" => customer_agent,
          "order-lookup" => order_agent
        }
      )

  ## Tool Interface

  The returned function expects a map with `:task` key:

      customer_agent.(%{"task" => "Find top customer by revenue"})
      #=> %{result: [...], summary: "...", refs: %{customer_id: 123}, trace: [...]}
  """
  @spec as_tool(keyword()) :: tool()
  def as_tool(opts)
end
```

---

### PtcRunner.SubAgent.Loop

```elixir
defmodule PtcRunner.SubAgent.Loop do
  @moduledoc """
  Multi-turn agentic execution loop.

  Manages the conversation between LLM and PTC-Lisp interpreter:

  1. LLM generates a program (or final answer)
  2. Program is executed via `PtcRunner.Lisp.run/2`
  3. Result (or error) is fed back to LLM
  4. Repeat until LLM answers without a program

  ## Features

  - Tool call recording for observability
  - Error recovery (errors fed back to LLM)
  - Token usage accumulation
  - Memory scoping (per-loop scratchpad)
  - Configurable termination (max_turns, answer detection)
  """

  @doc """
  Run the agentic loop until completion or failure.

  ## Options

  - `:llm` - Required. LLM callback function
  - `:tools` - Tool functions (default: `%{}`)
  - `:context` - Initial context values (default: `%{}`)
  - `:memory` - Initial memory state (default: `%{}`)
  - `:max_turns` - Maximum iterations (default: `5`)
  - `:timeout` - Per-program timeout (default: `5000`)
  - `:system_prompt` - Override default prompt

  ## Return Value

      {:ok, answer, trace, usage, final_memory}
      {:error, reason, trace, usage}
  """
  @spec run(String.t(), keyword()) ::
    {:ok, String.t(), [map()], map(), map()} |
    {:error, term(), [map()], map()}
  def run(task, opts)
end
```

---

### PtcRunner.SubAgent.RefExtractor

```elixir
defmodule PtcRunner.SubAgent.RefExtractor do
  @moduledoc """
  Deterministic value extraction from SubAgent results.

  Refs are extracted after the agentic loop completes, providing
  reliable values for chaining between SubAgents.

  ## Extraction Methods

  1. **Path-based** - Using Access paths
  2. **Function-based** - Using arbitrary functions

  ## Examples

      result = [%{id: 1, name: "Alice"}, %{id: 2, name: "Bob"}]

      refs = RefExtractor.extract(result, %{
        first_id: [Access.at(0), :id],      # Path-based
        count: &length/1,                    # Function-based
        names: fn r -> Enum.map(r, & &1.name) end
      })

      #=> %{first_id: 1, count: 2, names: ["Alice", "Bob"]}
  """

  @type spec :: [Access.access_fun(term(), term())] | (term() -> term())

  @doc """
  Extract values from a result using the given specs.

  Returns a map with the same keys as the spec map.
  Missing paths return `nil`.
  """
  @spec extract(term(), %{atom() => spec()}) :: map()
  def extract(result, specs)

  @doc """
  Validate that required refs are non-nil.

  Returns `{:ok, refs}` if all required refs are present,
  or `{:error, missing_keys}` listing which refs are nil.
  """
  @spec validate(map(), [atom()]) :: {:ok, map()} | {:error, [atom()]}
  def validate(refs, required_keys)
end
```

---

### PtcRunner.SubAgent.LLMTool

```elixir
defmodule PtcRunner.SubAgent.LLMTool do
  @moduledoc """
  LLM-powered tool wrapper for classification, evaluation, and judgment.

  Creates tools that call an LLM with a templated prompt and parse
  structured responses. Useful when a tool needs reasoning rather
  than deterministic computation.

  ## Example

      tools = %{
        "evaluate" => LLMTool.new(
          prompt: "Is this email urgent? Subject: {{subject}}",
          returns: %{urgent: :bool, reason: :string}
        )
      }

  The tool can then be called like any other:

      (call "evaluate" {:subject "Server down!"})
      ;; => {:urgent true :reason "Production issue"}
  """

  @type llm_ref :: :caller | atom() | (map() -> {:ok, String.t()} | {:error, term()})

  @type t :: %__MODULE__{
    prompt: String.t(),
    returns: map() | [map()],
    llm: llm_ref(),
    description: String.t() | nil
  }

  defstruct [:prompt, :returns, :llm, :description]

  @doc """
  Create a new LLM-powered tool.

  ## Schema Generation

  LLMTool automatically generates a typed schema from:
  - **Inputs**: Extracted from `{{var}}` template placeholders
  - **Outputs**: From the `:returns` specification

  Example:
      LLMTool.new(
        prompt: "Is {{email.subject}} urgent for {{customer_tier}} customer?",
        returns: %{urgent: :bool, reason: :string}
      )

  Generates schema:
      evaluate(email {:subject :string}, customer_tier :string) -> {:urgent :bool :reason :string}

  This enables the main agent to reason about data flow with LLM tools
  just like regular tools.

  ## Options

  - `:prompt` - Required. Template string with `{{var}}` placeholders.
    Supports Mustache-style iteration: `{{#items}}...{{/items}}`
    Nested access like `{{email.subject}}` infers nested type structure.
  - `:returns` - Required. Expected return structure for JSON parsing.
    Use a map for single object, list for array response.
  - `:llm` - Optional. LLM to use:
    - `:caller` (default) - Use the SubAgent's LLM
    - Atom (e.g., `:haiku`) - Look up from model registry
    - Function - Use directly as LLM callback
  - `:description` - Optional. Description for schema generation.

  ## Examples

      # Simple classification (uses caller's LLM)
      LLMTool.new(
        prompt: "Is {{text}} positive or negative?",
        returns: %{sentiment: :string, confidence: :float}
      )

      # Batch processing with cheaper model
      LLMTool.new(
        prompt: "Classify urgency for each: {{#items}}{{subject}}{{/items}}",
        returns: [%{id: :int, urgency: :string}],
        llm: :haiku
      )

      # With explicit LLM callback
      LLMTool.new(
        prompt: "...",
        returns: %{...},
        llm: fn input -> MyLLM.call(input) end
      )
  """
  @spec new(keyword()) :: t()
  def new(opts)
end
```

---

## LLM Callback Contract

The LLM callback is the integration point for any LLM provider.

### Signature

```elixir
@spec llm_callback(input :: map()) :: {:ok, String.t()} | {:error, term()}
```

### Input Structure

```elixir
%{
  system: "You are a PTC-Lisp agent. Query datasets using ```clojure blocks...",
  messages: [
    %{role: :user, content: "Find urgent emails"},
    %{role: :assistant, content: "```clojure\n(call \"list_emails\" {})\n```"},
    %{role: :user, content: "Result: [%{id: 1, subject: \"Urgent\"}]"},
    # ... conversation continues
  ]
}
```

### Output

- **Success:** `{:ok, "LLM response text"}` - May contain code blocks or final answer
- **Error:** `{:error, reason}` - Any error term

### Example Implementation

```elixir
# Minimal example (for testing)
fn %{system: _system, messages: messages} ->
  # Echo back a simple program
  {:ok, ~s'```clojure\n(+ 1 2)\n```'}
end

# With an HTTP-based LLM
fn %{system: system, messages: messages} ->
  body = %{
    model: "gpt-4",
    messages: [
      %{"role" => "system", "content" => system}
      | Enum.map(messages, fn %{role: r, content: c} ->
          %{"role" => to_string(r), "content" => c}
        end)
    ]
  }

  case Req.post("https://api.openai.com/v1/chat/completions",
         json: body,
         headers: [{"Authorization", "Bearer #{api_key}"}]) do
    {:ok, %{status: 200, body: %{"choices" => [%{"message" => %{"content" => text}} | _]}}} ->
      {:ok, text}
    {:ok, %{status: status, body: body}} ->
      {:error, {:api_error, status, body}}
    {:error, reason} ->
      {:error, reason}
  end
end
```

---

## Implementation Hints

Based on the spike validation (`spike-subagent` branch).

### System Prompt Generation

The `Prompt` module generates system prompts with tool schemas extracted automatically:

```elixir
defmodule PtcRunner.SubAgent.Prompt do
  def generate(opts) do
    tools = Keyword.get(opts, :tools, %{})
    tool_catalog = Keyword.get(opts, :tool_catalog, %{})

    """
    #{base_prompt()}

    #{tools_section(tools)}

    #{tool_catalog_section(tool_catalog)}

    #{context_section(opts)}
    """
  end

  defp tools_section(tools) when tools == %{}, do: ""
  defp tools_section(tools) do
    schemas = extract_schemas(tools)
    """
    ## Tools you can call
    #{format_schemas(schemas)}
    """
  end

  defp tool_catalog_section(catalog) when catalog == %{}, do: ""
  defp tool_catalog_section(catalog) do
    schemas = extract_schemas(catalog)
    """
    ## Tools available for planning (do not call directly)
    #{format_schemas(schemas)}
    """
  end
end
```

When `tool_catalog` is provided, the LLM sees tool schemas in the prompt but cannot call them directly. This is useful for planning agents that need to understand available tools to create execution plans.

**Example generated prompt:**

```
You are a PTC-Lisp agent...

## Tools you can call
- create_plan(steps [{:id :keyword :task :string :tools [:string] :needs [:keyword]}]) -> {:status :string}

## Tools available for planning (do not call directly)
- email-finder: agent(task :string) -> {:summary :string :refs {:email_ids [:int] :count :int}}
- email-reader: agent(task :string, context :map) -> {:summary :string :refs {:bodies :map}}
- reply-drafter: agent(task :string, context :map) -> {:summary :string :refs {:draft_ids [:int]}}
```

---

### Loop Implementation

```elixir
defmodule PtcRunner.SubAgent.Loop do
  def run(task, opts) do
    llm = Keyword.fetch!(opts, :llm)
    tools = Keyword.get(opts, :tools, %{})
    max_turns = Keyword.get(opts, :max_turns, 5)
    timeout = Keyword.get(opts, :timeout, 5000)

    # Build initial context
    context = build_context(opts)
    system_prompt = Keyword.get_lazy(opts, :system_prompt, fn ->
      PtcRunner.SubAgent.Prompt.generate(opts)
    end)

    # Initialize state
    state = %{
      messages: [%{role: :user, content: task}],
      memory: Keyword.get(opts, :memory, %{}),
      trace: [],
      usage: zero_usage(),
      iteration: max_turns
    }

    loop(llm, system_prompt, tools, context, timeout, state)
  end

  defp loop(_llm, _system, _tools, _ctx, _timeout, %{iteration: 0} = state) do
    {:error, :max_turns_reached, state.trace, state.usage}
  end

  defp loop(llm, system, tools, ctx, timeout, state) do
    # 1. Call LLM
    case llm.(%{system: system, messages: state.messages}) do
      {:ok, response} ->
        state = update_usage(state, response)

        # 2. Extract program or detect answer
        case extract_program(response) do
          {:program, code} ->
            # 3. Execute program
            case execute(code, tools, ctx, state.memory, timeout) do
              {:ok, result, tool_calls, new_memory} ->
                # 4. Record and continue
                state = record_success(state, code, result, tool_calls, new_memory)
                state = append_result_message(state, result)
                loop(llm, system, tools, update_ctx(ctx, result), timeout, state)

              {:error, reason} ->
                # Feed error back to LLM
                state = record_error(state, code, reason)
                state = append_error_message(state, reason)
                loop(llm, system, tools, ctx, timeout, state)
            end

          {:answer, text} ->
            # Done - LLM responded without program
            state = record_answer(state, text)
            {:ok, text, state.trace, state.usage, state.memory}
        end

      {:error, reason} ->
        {:error, {:llm_error, reason}, state.trace, state.usage}
    end
  end

  defp execute(code, tools, ctx, memory, timeout) do
    tool_calls = []  # Accumulator for recording

    tool_fn = fn name, args ->
      case Map.fetch(tools, name) do
        {:ok, fun} ->
          result = fun.(args)
          # Record call (side effect via process dictionary or agent)
          record_tool_call(name, args, result)
          result
        :error ->
          raise "Unknown tool: #{name}"
      end
    end

    case PtcRunner.Lisp.run(code,
           tools: tool_fn,
           context: ctx,
           memory: memory,
           timeout: timeout) do
      {:ok, result, _delta, new_memory} ->
        {:ok, result, get_recorded_calls(), new_memory}
      {:error, reason} ->
        {:error, reason}
    end
  end
end
```

### Program Extraction

```elixir
defp extract_program(response) do
  # Look for ```clojure or ```lisp code blocks
  case Regex.run(~r/```(?:clojure|lisp)?\s*([\s\S]+?)```/, response) do
    [_, code] -> {:program, String.trim(code)}
    nil -> {:answer, response}
  end
end
```

### RefExtractor Implementation

```elixir
defmodule PtcRunner.SubAgent.RefExtractor do
  def extract(result, specs) when is_map(specs) do
    Map.new(specs, fn {key, spec} ->
      {key, extract_one(result, spec)}
    end)
  end

  defp extract_one(result, path) when is_list(path) do
    get_in(result, path)
  rescue
    _ -> nil
  end

  defp extract_one(result, fun) when is_function(fun, 1) do
    fun.(result)
  rescue
    _ -> nil
  end

  def validate(refs, required_keys) do
    missing = Enum.filter(required_keys, fn key ->
      Map.get(refs, key) == nil
    end)

    case missing do
      [] -> {:ok, refs}
      keys -> {:error, keys}
    end
  end
end
```

### Tool Call Recording

Use process dictionary or an Agent to record tool calls during execution:

```elixir
defp record_tool_call(name, args, result) do
  calls = Process.get(:tool_calls, [])
  Process.put(:tool_calls, [{name, args, result} | calls])
end

defp get_recorded_calls do
  calls = Process.get(:tool_calls, [])
  Process.delete(:tool_calls)

  calls
  |> Enum.reverse()
  |> Enum.map(fn {name, args, result} ->
    %{name: name, args: args, result: result}
  end)
end
```

---

## Context Variables

Available in PTC-Lisp programs via `ctx/` prefix:

| Variable | Description |
|----------|-------------|
| `ctx/key` | User-provided context values |
| `ctx/last-result` | Result of previous turn's program |

## Memory Operations

Per-agent scoped memory via PTC-Lisp:

```clojure
(memory/put :key value)    ; Store value
(memory/get :key)          ; Retrieve value
memory/key                 ; Shorthand access
```

---

## Error Handling

### Ref Retry Flow

When required refs are nil, the agent gets another chance:

1. Execute loop until answer
2. Extract refs
3. If required refs nil and retries remaining:
   - Feed error message to LLM
   - Continue loop
4. If still nil, return error to caller

```elixir
def delegate(task, opts) do
  refs_spec = Keyword.get(opts, :refs, %{})
  required = extract_required_keys(refs_spec)
  max_retries = Keyword.get(opts, :max_ref_retries, 1)

  do_delegate(task, opts, refs_spec, required, max_retries)
end

defp do_delegate(task, opts, refs_spec, required, retries) do
  case Loop.run(task, opts) do
    {:ok, answer, trace, usage, memory} ->
      result = extract_result(answer, memory)
      refs = RefExtractor.extract(result, refs_spec)

      case RefExtractor.validate(refs, required) do
        {:ok, _} ->
          {:ok, build_result(result, answer, refs, trace, usage)}

        {:error, missing} when retries > 0 ->
          # Retry with error feedback
          error_msg = format_ref_error(missing, result, refs_spec)
          new_opts = append_message(opts, error_msg)
          do_delegate(task, new_opts, refs_spec, required, retries - 1)

        {:error, missing} ->
          {:error, %{reason: {:missing_refs, missing}, trace: trace, usage: usage}}
      end

    {:error, _, _, _} = err ->
      err
  end
end
```

---

## Test Strategy

### Unit Tests

```elixir
# RefExtractor
test "extracts values using Access paths"
test "extracts values using functions"
test "returns nil for missing paths"
test "validates required refs"

# Loop
test "single-turn completion"
test "multi-turn with tool calls"
test "error recovery feeds back to LLM"
test "max_turns terminates loop"
test "tool calls recorded in trace"
test "memory persists across turns"

# SubAgent
test "delegate with mock LLM"
test "as_tool returns callable function"
test "refs extracted after completion"
test "ref retry on missing required refs"
test "nested SubAgents (as_tool in tools)"

# Prompt
test "generates tools section with schemas"
test "generates tool_catalog section separately"
test "extracts @spec from function references"
test "uses explicit spec when provided"
test "skips schema when :skip marker used"

# LLMTool
test "renders template with args"
test "extracts input schema from template placeholders"
test "generates output schema from returns spec"
test "calls caller LLM by default"
test "calls specified LLM when provided"
test "parses JSON response to returns schema"
test "handles batch returns (list schema)"
test "infers nested types from {{obj.field}} syntax"
```

### Integration Tests

```elixir
# With real LLM (optional, behind flag)
test "end-to-end task delegation"
test "chained SubAgents pass refs"
test "plan generation via create_plan tool"
test "tool_catalog schemas visible but not callable"
test "multi-turn ReAct pattern with memory"
test "LLMTool classification in agentic loop"
```

### Known LLM Behavior Issues

From spike testing with Gemini 2.5 Flash:

1. **Missing functions**: LLM tries `(str ...)` and `(conj ...)` which are currently missing
2. **Data Path Confusion**: Uses `[:result :id]` instead of `[:result 0 :id]` for list-wrapped results
3. **Invalid comparators**: Uses `(sort-by :total >)` but `>` isn't a valid comparator function

**Mitigations:**
- Add `str` and `conj` to `PtcRunner.Lisp.Runtime`
- Add numeric safety (handling `nil` in arithmetic)
- Add custom comparator support to `sort-by`

---

## Migration from Spike

The spike code in `demo/lib/ptc_demo/` should be:

1. **Moved to core:** `AgenticLoop` → `PtcRunner.SubAgent.Loop`
2. **Moved to core:** `RefExtractor` → `PtcRunner.SubAgent.RefExtractor`
3. **Adapted:** `SubAgent` → `PtcRunner.SubAgent` (remove ReqLLM dependency)
4. **Kept in demo:** `LispAgent`, `ModelRegistry`, LLM helpers

---

## Open Questions

1. **Usage extraction:** How to extract token counts from LLM callback?
   - Option A: Callback returns `{:ok, text, usage}`
   - Option B: Separate `:usage_callback` option
   - Option C: Don't track (demo concern only)

2. **Streaming:** Should the callback support streaming?
   - Probably out of scope for v1

3. **System prompt customization:** Full override or composable parts?

---

## Related Documents

- [Tutorial](tutorial.md) - Usage guide and examples
- [Spike Summary](spike-summary.md) - Validation results
- [PtcRunner Guide](../guide.md) - Core PTC-Lisp documentation
