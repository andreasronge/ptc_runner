# PtcRunner.SubAgent Specification

> **Status:** Draft specification based on spike validation (branch: `spike-subagent`)

This document specifies the core SubAgent API for inclusion in the PtcRunner library.

## Overview

A SubAgent is an isolated worker that executes missions using PTC-Lisp programs generated by an LLM. The core library provides:
 
- **`PtcRunner.SubAgent`** - Main API for mission delegation
- **`PtcRunner.SubAgent.Loop`** - Multi-turn agentic execution
- **`PtcRunner.SubAgent.Signature`** - Functional contracts and validation

The LLM integration is callback-based with no external dependencies.

## Module Structure

```
lib/ptc_runner/
├── sub_agent.ex                 # Main API
└── sub_agent/
    ├── loop.ex                  # Agentic loop implementation
    ├── step.ex                  # Standard result structure
    ├── prompt.ex                # System prompt generation
    ├── signature.ex             # Signature parsing and validation
    ├── schema_extractor.ex      # Tool type extraction from @spec
    └── llm_tool.ex              # LLM-powered tool wrapper
```

---

## Architecture Overview

### Execution Flow (Step-wise Agentic Loop)

The Agentic Loop treats every LLM turn as a **Step**. The output of Turn N becomes the input (Context) for Turn N+1.

```
delegate/2
    │
    ├─► Prompt.generate/1 ──► Extract schemas from context + tools + tool_catalog
    │                         Generate system prompt with "Data Inventory"
    │
    └─► Loop.run/2
            │
            ├─► LLM callback ──► Returns program or text-reasoning
            │
            ├─► PtcRunner.Lisp.run/2 ──► Execute turn-program
            │       │
            │       └─► Result wrapped into a PtcRunner.Step
            │
            ├─► Turn Termination Check:
            │       ├─► (call "return" ...) ──► Stop, Return {:ok, step}
            │       └─► (call "fail" ...)   ──► Stop, Return {:error, step}
            │
            └─► Feedback & Turn Merge:
                    ├─► LLM History: Append Step.return (Public) + Signature
                    ├─► Lisp Context: Merge Step.return (Full) into ctx/
                    └─► Next Turn: Goto LLM callback
```


### Tool Normalization & Schema Extraction

All tools are normalized into a internal `Tool` representation. This ensures consistency between different registration syntaxes.

1.  **Function references** (`&Fun/n`): Extract `@spec` to populate `ToolSpec`.
2.  **String shorthand** (`{fun, "(...) -> ..."}`): Parser converts string to `ToolSpec`.
3.  **Explicit structs**: Pass `ToolSpec` or `LLMTool` directly.
4.  **SubAgent-as-Tool**: The sub-agent's signature is used as the tool's schema.

Generated schemas follow the `name(params) -> returns` format:
```
search(query :string, limit :int) -> [{:id :int :title :string}]
email-agent(prompt :string) -> {summary :string, count :int, _email_ids [:int]}
```


### tools vs tool_catalog

| Aspect | `tools` | `tool_catalog` |
|--------|---------|----------------|
| Schema in prompt | ✓ "Tools you can call" | ✓ "Tools for planning (do not call)" |
| Callable by agent | ✓ Yes | ✗ No |
| Use case | Execution tools | Planning visibility |

This separation enables planning agents to see what tools exist (with types) without being able to call them prematurely.

---

## API Specification

### PtcRunner.SubAgent

```elixir
defmodule PtcRunner.SubAgent do
  @moduledoc """
  Isolated mission execution with context efficiency.
 
  SubAgents execute missions using PTC-Lisp programs generated by an LLM.
  Each SubAgent runs in isolation with its own tools, context, and memory.

  ## Example

      llm = fn %{system: sys, messages: msgs} ->
        # Call your LLM provider
        {:ok, "```clojure\\n(call \\"get_data\\" {})\\n```"}
      end

      {:ok, step} = PtcRunner.SubAgent.delegate(
        "Find the top customer",
        llm: llm,
        tools: %{"get_customers" => &MyApp.get_customers/1}
      )
 
      step.return.summary  #=> "Top customer is Acme Corp with $1.2M revenue"
  """

  # ============================================================
  # Types
  # ============================================================

  @typedoc "LLM callback function"
  @type llm :: (llm_input() -> {:ok, String.t()} | {:error, term()})

  @typedoc "Input passed to LLM callback"
  @type llm_input :: %{
    required(:system) => String.t(),
    required(:messages) => [message()]
  }

  @typedoc "Conversation message"
  @type message :: %{
    required(:role) => :user | :assistant,
    required(:content) => String.t()
  }

  @typedoc "Tool function - receives args map, returns any term"
  @type tool :: (map() -> term())


  @typedoc "Successful Step result"
  @type result :: %{
    required(:return) => map(),
    required(:fail) => map() | nil,
    required(:signature) => String.t(),
    required(:mem) => map(),
    required(:trace) => [trace_entry()],
    required(:usage) => usage()
  }

  @typedoc "Single turn in execution trace"
  @type trace_entry :: %{
    required(:iteration) => pos_integer(),
    optional(:program) => String.t(),
    optional(:result) => term(),
    optional(:error) => term(),
    optional(:answer) => String.t(),
    optional(:tool_calls) => [tool_call()],
    required(:usage) => usage()
  }

  @typedoc "Tool call record"
  @type tool_call :: %{
    required(:name) => String.t(),
    required(:args) => map(),
    required(:result) => term()
  }

  @typedoc "Token usage statistics"
  @type usage :: %{
    required(:input_tokens) => non_neg_integer(),
    required(:output_tokens) => non_neg_integer(),
    required(:total_tokens) => non_neg_integer(),
    required(:requests) => non_neg_integer()
  }

  @typedoc "Error result"
  @type error :: %{
    required(:reason) => term(),
    required(:trace) => [trace_entry()],
    required(:usage) => usage()
  }

  # ============================================================
  # Main API
  # ============================================================

  @doc """
  Delegate a prompt to an isolated sub-agent.
 
  The sub-agent generates PTC-Lisp programs to accomplish the mission,
  executing them in a sandboxed environment with access to the
  provided tools.
 
  ## Required Options
 
  - `:llm` - Callback function for LLM calls (see `t:llm/0`)
 
  ## Options
 
  - `:signature` - Desired return structure: `"() -> {field :type}"`.
  - `:tools` - Map of callable tools (default: `%{}`)
  - `:tool_catalog` - Non-callable tools for planning (default: `%{}`)
  - `:context` - Values available as `ctx/` in PTC-Lisp (default: `%{}`)
  - `:context_signature` - Signature of the provided context for type propagation.
  - `:max_turns` - Maximum LLM calls before failing (default: `5`)
  - `:timeout` - Per-program execution timeout in ms (default: `5000`)
  - `:prompt_limit` - Max items/bytes shown in LLM prompt for Large Data. (default: `%{list: 5, string: 1000}`)
 
  ## Return Value
 
  On success, returns `{:ok, %PtcRunner.Step{}}`.
  On failure, returns `{:error, %PtcRunner.Step{}}`.
 
  ## Examples
 
      # Basic usage
      {:ok, step} = PtcRunner.SubAgent.delegate(
        "List all products",
        llm: my_llm,
        tools: %{"get_products" => &Shop.list_products/1}
      )
 
      # With signature for chaining
      {:ok, step1} = PtcRunner.SubAgent.delegate(
        "Find urgent emails",
        signature: "() -> {count :int, _email_ids [:int]}",
        llm: my_llm,
        tools: email_tools
      )
 
      # Pass results to next step via context_signature
      {:ok, step2} = PtcRunner.SubAgent.delegate(
        "Draft replies",
        llm: my_llm,
        tools: draft_tools,
        context: step1.return,
        context_signature: step1.signature
      )
  """
  @spec delegate(String.t(), keyword()) :: {:ok, result()} | {:error, error()}
  def delegate(prompt, opts)

  @doc """
  Wrap a SubAgent or Prompt configuration as a callable tool.
 
  Tools are either "Judgment Tools" (single-turn) or "Agent Tools" (multi-turn).
  The distinction is implicit: if `tools:` is provided, it's an Agent Tool.
 
  ## Configuration
 
  - `:prompt` - Required. Templated string mission (e.g., `"Summarize {{text}}"`).
  - `:signature` - Required. Input and Output contract. Inputs must match placeholders.
  - `:llm` - Required. LLM callback.
  - `:tools` - Optional. If provided, the tool executes as a multi-turn SubAgent.
 
  ## Example
 
      email_tool = PtcRunner.SubAgent.as_tool(
        prompt: "Find emails matching: {{query}}",
        signature: "(query :string) -> {count :int, _email_ids [:int]}",
        llm: my_llm,
        tools: email_tools
      )
 
  The parent LLM sees a tool schema derived from the signature and prompt:
  `email_tool(query :string) -> {count :int, _email_ids [:int]}`
  """
  @spec as_tool(keyword() | map()) :: tool()
  def as_tool(opts_or_map)

end
```

---

### PtcRunner.SubAgent.Loop

```elixir
defmodule PtcRunner.SubAgent.Loop do
  @moduledoc """
  Multi-turn agentic execution loop.

  Manages the conversation between LLM and PTC-Lisp interpreter:
 
  1. LLM generates a program (Turn Turn)
  2. Program is executed and wrapped in a `PtcRunner.Step`.
  3. Step results (Public) are fed back to LLM history.
  4. Step results (Full) are merged into `ctx/` for the next Turn.
  5. Repeat until the LLM calls `return` or `fail` tools.
 
  ## Features
 
  - **Implicit Chaining**: Every turn's results are merged into context.
  - **Strict Termination**: Mission only ends on explicit `return`/`fail`.
  - **Data Privacy**: Firewalled data (`_`) is hidden in history but available in Lisp.
  - **Boundary Reminders**: Auto-prompts if the LLM provides text without a program.
  """

  @doc """
  Run the agentic loop until completion or failure.

  ## Options
 
  - `:llm` - Required. LLM callback function
  - `:tools` - Tool functions (default: `%{}`)
  - `:context` - Initial context values (default: `%{}`)
  - `:memory` - Initial memory state (default: `%{}`)
  - `:max_turns` - Maximum iterations (default: `5`)
  - `:timeout` - Per-program timeout (default: `5000`)
  - `:system_prompt` - Override default prompt
  - `:prompt_limit` - Truncation limits for Large Data.
 
  ## Return Value
  
      {:ok, %PtcRunner.Step{}}
      {:error, %PtcRunner.Step{}}
  """
  @spec run(String.t(), keyword()) ::
    {:ok, %PtcRunner.Step{}} |
    {:error, %PtcRunner.Step{}}
  def run(prompt, opts)
end
```

---

### PtcRunner.SubAgent.Signature
 
```elixir
defmodule PtcRunner.SubAgent.Signature do
  @moduledoc """
  Functional contracts for Agents and Tools.
  """
 
  @doc """
  Parses a signature string into a structured spec.
  Handles '->' extraction for context propagation.
  """
  @spec parse(String.t()) :: {:ok, map()} | {:error, term()}
  def parse(sig_string)
 
  @doc """
  Extracts ONLY the return part of a signature.
  Used by 'context_signature' to propagate types from Step 1 to Step 2.
  """
  @spec extract_return_spec(String.t()) :: String.t()
  def extract_return_spec(full_signature)
end
```


---

### PtcRunner.SubAgent.LLMTool

```elixir
defmodule PtcRunner.SubAgent.LLMTool do
  @moduledoc """
  LLM-powered tool wrapper for classification, evaluation, and judgment.

  Creates tools that call an LLM with a templated prompt and parse
  structured responses. Useful when a tool needs reasoning rather
  than deterministic computation.

  ## Example

      tools = %{
        "evaluate" => LLMTool.new(
          prompt: "Is this email urgent? Subject: {{subject}}",
          signature: "(subject :string) -> {urgent: :bool, reason: :string}"
        )
      }

  The tool can then be called like any other:

      (call "evaluate" {:subject "Server down!"})
      ;; => {:urgent true :reason "Production issue"}
  """

  @type llm_ref :: :caller | atom() | (map() -> {:ok, String.t()} | {:error, term()})

  @type t :: %__MODULE__{
    prompt: String.t(),
    signature: String.t(),
    llm: llm_ref(),
    description: String.t() | nil,
    tools: map() | nil
  }

  defstruct [:prompt, :signature, :llm, :description, :tools]

  @doc """
  Create a new LLM-powered tool.
 
  ## Schema Generation
 
  LLMTool automatically generates a typed schema from:
  - **Inputs**: Extracted from `{{var}}` template placeholders
  - **Outputs**: From the `:signature` specification
 
  Example:
      LLMTool.new(
        prompt: "Is {{email.subject}} urgent for {{customer_tier}} customer?",
        signature: "(email {subject :string}, customer_tier :string) -> {urgent :bool, reason :string}"
      )
 
  Generates schema:
      evaluate(email {:subject :string}, customer_tier :string) -> {urgent :bool, reason :string}
 
  ## Options
 
  - `:prompt` - Required. Template string with `{{var}}` placeholders.
  - `:signature` - Required. The functional contract string.
  - `:llm` - Optional. LLM to use:
    - `:caller` (default) - Use the SubAgent's LLM
    - Atom (e.g., `:haiku`) - Look up from model registry
    - Function - Use directly as LLM callback
  - `:description` - Optional. Description for schema generation.
  - `:tools` - Optional. If provided, the tool executes as a multi-turn SubAgent.

  ## Examples

      # Simple classification (uses caller's LLM)
      LLMTool.new(
        prompt: "Is {{text}} positive or negative?",
        signature: "(text :string) -> {sentiment: :string, confidence: :float}"
      )

      # Batch processing with cheaper model
      LLMTool.new(
        prompt: "Classify urgency for each: {{#items}}{{subject}}{{/items}}",
        signature: "(items [{subject :string}]) -> [{id: :int, urgency: :string}]",
        llm: :haiku
      )

      # With explicit LLM callback
      LLMTool.new(
        prompt: "...",
        signature: "...",
        llm: fn input -> MyLLM.call(input) end
      )
  """
  @spec new(keyword()) :: t()
  def new(opts)
end
```

---

### Tool Configuration (Unified Model)
 
Tools are defined as maps. The system automatically promotes them to "Judgment Tools" or "Agent Tools" based on the presence of `tools:`.
 
```elixir
# Single-turn Judgment Tool
"classifier" => %{
  prompt: "Is {{text}} positive?",
  signature: "(text :string) -> {is_positive :bool}"
}
 
# Multi-turn Agent Tool
"researcher" => %{
  prompt: "Conduct research on {{topic}}",
  signature: "(topic :string) -> {summary :string, _refs [:map]}",
  tools: web_search_tools,
  llm: high_res_model
}
```
 
### Nested Data & Expansion
 
Signatures support nesting, and prompts can use dot-notation for expansion.
 
```elixir
"profile-agent" => %{
  prompt: "Analyze profile for {{user.name}} (ID: {{user.id}})",
  signature: "(user {name :string, id :int}) -> {summary :string}"
}
```
 
### Validation Rules
 
1.  **Placeholder Match**: Every `{{key}}` in the `prompt` must exist as a parameter in the `signature`.
2.  **Type Safety**: The arguments passed to a tool call are validated against the signature's input types.
3.  **Implicit Conversion**: PTC-Lisp `(call "tool" {...})` arguments are converted to the signature types (e.g., string to int) if possible.

---

## LLM Callback Contract

The LLM callback is the integration point for any LLM provider.

### Signature

```elixir
@spec llm_callback(input :: map()) :: {:ok, String.t()} | {:error, term()}
```

### Input Structure

```elixir
%{
  system: "You are a PTC-Lisp agent. Query datasets using ```clojure blocks...",
  messages: [
    %{role: :user, content: "Find urgent emails"},
    %{role: :assistant, content: "```clojure\n(call \"list_emails\" {})\n```"},
    %{role: :user, content: "Result: [%{id: 1, subject: \"Urgent\"}]"},
    # ... conversation continues
  ]
}
```

### Output

- **Success:** `{:ok, "LLM response text"}` - May contain code blocks or final answer
- **Error:** `{:error, reason}` - Any error term

### Example Implementation

```elixir
# Minimal example (for testing)
fn %{system: _system, messages: messages} ->
  # Echo back a simple program
  {:ok, ~s'```clojure\n(+ 1 2)\n```'}
end

# With an HTTP-based LLM
fn %{system: system, messages: messages} ->
  body = %{
    model: "gpt-4",
    messages: [
      %{"role" => "system", "content" => system}
      | Enum.map(messages, fn %{role: r, content: c} ->
          %{"role" => to_string(r), "content" => c}
        end)
    ]
  }

  case Req.post("https://api.openai.com/v1/chat/completions",
         json: body,
         headers: [{"Authorization", "Bearer #{api_key}"}]) do
    {:ok, %{status: 200, body: %{"choices" => [%{"message" => %{"content" => text}} | _]}}} ->
      {:ok, text}
    {:ok, %{status: status, body: body}} ->
      {:error, {:api_error, status, body}}
    {:error, reason} ->
      {:error, reason}
  end
end
```

---

## Implementation Hints

Based on the spike validation (`spike-subagent` branch).

### System Prompt Generation

The `Prompt` module generates system prompts with tool schemas extracted automatically:

```elixir
defmodule PtcRunner.SubAgent.Prompt do
  def generate(opts) do
    tools = Keyword.get(opts, :tools, %{})
    tool_catalog = Keyword.get(opts, :tool_catalog, %{})

    """
    #{base_prompt()}

    #{tools_section(tools)}

    #{tool_catalog_section(tool_catalog)}

    #{context_section(opts)}
    """
  end

  defp tools_section(tools) when tools == %{}, do: ""
  defp tools_section(tools) do
    schemas = extract_schemas(tools)
    """
    ## Tools you can call
    #{format_schemas(schemas)}
    """
  end

  defp tool_catalog_section(catalog) when catalog == %{}, do: ""
  defp tool_catalog_section(catalog) do
    schemas = extract_schemas(catalog)
    """
    ## Tools available for planning (do not call directly)
    #{format_schemas(schemas)}
    """
  end
end
```

When `tool_catalog` is provided, the LLM sees tool schemas in the prompt but cannot call them directly. This is useful for planning agents that need to understand available tools to create execution plans.

**Example generated prompt:**
 
```
You are a PTC-Lisp agent...
 
## Tools you can call
- create_plan(steps [{id :keyword, prompt :string, tools [:string], needs [:keyword]}]) -> {status :string}
 
## Tools available for planning (do not call directly)
- email-finder: (prompt :string) -> {summary :string, count :int, _email_ids [:int]}
- email-reader: (prompt :string, email_ids [:int]) -> {bodies :map}
- reply-drafter: (prompt :string, bodies :map) -> {draft_ids [:int]}
```

---

### Loop Implementation

```elixir
defmodule PtcRunner.SubAgent.Loop do
  def run(prompt, opts) do
    llm = Keyword.fetch!(opts, :llm)
    tools = Keyword.get(opts, :tools, %{})
    max_turns = Keyword.get(opts, :max_turns, 5)
    timeout = Keyword.get(opts, :timeout, 5000)

    # Build initial context
    context = build_context(opts)
    system_prompt = Keyword.get_lazy(opts, :system_prompt, fn ->
      PtcRunner.SubAgent.Prompt.generate(opts)
    end)

    # Initialize state
    state = %{
      messages: [%{role: :user, content: prompt}],
      memory: Keyword.get(opts, :memory, %{}),
      trace: [],
      usage: zero_usage(),
      iteration: max_turns
    }

    loop(llm, system_prompt, tools, context, timeout, state)
  end

  defp loop(llm, system, tools, ctx, timeout, state) do
    # 1. Call LLM
    case llm.(%{system: system, messages: state.messages}) do
      {:ok, response} ->
        state = update_usage(state, response)
 
        case extract_program(response) do
          {:program, code} ->
            # 2. Execute program (returns Turn Step)
            case execute(code, tools, ctx, state.memory, timeout) do
              {:ok, :return, data, new_mem} ->
                # SUCCESS: TERMINATE
                {:ok, build_step(data, new_mem, state)}
 
              {:ok, :fail, data, new_mem} ->
                # FAILURE: TERMINATE
                {:error, build_step(data, new_mem, state)}
 
              {:ok, turn_result, new_mem} ->
                # TURN COMPLETED: MERGE AND LOOP
                # 1. Merge all turn results into ctx/ for the next turn
                new_ctx = Map.merge(ctx, turn_result)
                # 2. Update messages with public view of the Step
                state = append_step_feedback(state, turn_result)
                
                loop(llm, system, tools, new_ctx, timeout, %{state | memory: new_mem})
 
              {:error, reason} ->
                # TURN ERROR: FEED ERROR BACK
                new_ctx = Map.put(ctx, :fail, reason)
                state = append_error_feedback(state, reason)
                loop(llm, system, tools, new_ctx, timeout, state)
            end
 
          {:answer, text} ->
            # NO PROGRAM: BOUNDARY REMINDER
            state = append_reminder(state)
            loop(llm, system, tools, ctx, timeout, state)
        end
 
      {:error, reason} ->
        {:error, {:llm_error, reason}}
    end
  end

  defp execute(code, tools, ctx, memory, timeout) do
    # Built-in tools like 'fail' are injected here
    all_tools = Map.put(tools, "fail", fn args -> 
      throw {:fail, args}
    end)

    case PtcRunner.Lisp.run(code, tools: all_tools, context: ctx, ...) do
      # ...
    end
  end

end
```

### Program Extraction

```elixir
defp extract_program(response) do
  # Look for ```clojure or ```lisp code blocks
  case Regex.run(~r/```(?:clojure|lisp)?\s*([\s\S]+?)```/, response) do
    [_, code] -> {:program, String.trim(code)}
    nil -> {:answer, response}
  end
end
```

## Memory Operations
 
Per-agent scoped memory via PTC-Lisp:
 
```clojure
(mem/put :key value)    ; Store value
(mem/get :key)          ; Retrieve value
mem/key                 ; Shorthand access
```

---

## Test Strategy
 
### Unit Tests
 
```elixir
# Signature
test "parses signature string"
test "validates prompt placeholders match signature inputs"
test "extracts return part for context_signature"
test "handles nested signature types"
 
# Loop
test "single-turn completion via return tool"
test "multi-turn with tool calls and context merging"
test "feedback loop with public vs private visibility"
test "oversion/truncation of large results in prompt"
test "boundary reminder on plain text response"
test "max_turns terminates loop"
 
# SubAgent
test "delegate with prompt and signature"
test "implicit promotion of map to tool"
test "nested SubAgents (tools in tool config)"
 
# Prompt
test "generates tools section with schemas"
test "extracts @spec from function references"
```
```

### Integration Tests

```elixir
# With real LLM (optional, behind flag)
test "end-to-end mission delegation"
test "chained SubAgents pass data"
test "plan generation via create_plan tool"
test "tool_catalog schemas visible but not callable"
test "multi-turn ReAct pattern with memory"
test "LLMTool classification in agentic loop"
```

### Known LLM Behavior Issues

From spike testing with Gemini 2.5 Flash:

1. **Missing functions**: LLM tries `(str ...)` and `(conj ...)` which are currently missing
2. **Data Path Confusion**: Uses `[:result :id]` instead of `[:result 0 :id]` for list-wrapped results
3. **Invalid comparators**: Uses `(sort-by :total >)` but `>` isn't a valid comparator function

**Mitigations:**
- Add `str` and `conj` to `PtcRunner.Lisp.Runtime`
- Add numeric safety (handling `nil` in arithmetic)
- Add custom comparator support to `sort-by`

---

## Migration from Spike
 
The spike code in `demo/lib/ptc_demo/` should be:
 
1. **Moved to core:** `AgenticLoop` → `PtcRunner.SubAgent.Loop`
2. **Standardized:** Replace `RefExtractor` with `PtcRunner.SubAgent.Signature`
3. **Adapted:** `SubAgent` → `PtcRunner.SubAgent` (remove ReqLLM dependency)

---

## Open Questions

1. **Usage extraction:** How to extract token counts from LLM callback?
   - Option A: Callback returns `{:ok, text, usage}`
   - Option B: Separate `:usage_callback` option
   - Option C: Don't track (demo concern only)

2. **Streaming:** Should the callback support streaming?
   - Probably out of scope for v1

3. **System prompt customization:** Full override or composable parts?

---

## Future Work

### CLI Commands

Interactive SubAgent commands for the demo CLI:

```
> /subagent "Find the employee with highest expenses"
[SubAgent] Executing: (-> (call "get_expenses") ...)
[SubAgent] Result: "John Smith - $12,450"

> /subagent:verbose "Find top 3 products"
[SubAgent] Shows full trace with programs and tool calls
```

### Tool Discovery

For large tool registries (50+ tools), let SubAgents discover relevant tools:

```elixir
{:ok, result} = PtcRunner.ToolDiscovery.run(
  "Analyze travel expenses for Q3",
  llm: llm,
  registry: all_company_tools  # 100+ tools
)

# Discovery agent finds and uses only: get_expenses, get_categories, sum_by
```

### Plan Persistence

Save and resume plans:

```elixir
# File-based
Plan.save(plan, "plans/workflow-001.json")
{:ok, plan} = Plan.load("plans/workflow-001.json")

# GitHub Issues (collaborative, auditable)
{:ok, plan} = Plan.from_github_issue("owner/repo", 275)
Plan.sync_to_github(plan)  # Updates issue with execution history
```

### Parallel SubAgents

Run multiple SubAgents concurrently:

```elixir
prompts = [
  {"Jira", "Summarize sprint status", jira_tools},
  {"Slack", "Check urgent mentions", slack_tools},
  {"GitHub", "List PRs needing review", github_tools}
]

results =
  prompts
  |> Task.async_stream(fn {name, prompt, tools} ->
    {:ok, step} = PtcRunner.SubAgent.delegate(prompt, llm: llm, tools: tools)
    {name, step.summary}
  end, max_concurrency: 3)
  |> Enum.map(fn {:ok, result} -> result end)
```

**Note:** Memory isolation (scoped scratchpad) enables safe parallel execution.

---

---

## Related Documents

- [Tutorial](tutorial.md) - Usage guide and examples
- [Spike Summary](spike-summary.md) - Validation results
- [PtcRunner Guide](../guide.md) - Core PTC-Lisp documentation
